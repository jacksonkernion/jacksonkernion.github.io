---
title: "Strange Experience: Why Experience Without Access Makes No Sense"

author: Jackson Kernion

date: "February 20, 2017"

layout: paper

abstract: |
    According to a widely held view, we have two separate ways of thinking about 'consciousness'. We can think of 'conscious' mental states as '_experiency_'--as feeling a certain way or as having certain qualitative aspects--or we can think of 'conscious' mental states in a _functional_ way--as being available for arbitrary use. Importantly, these are _conceptually distinct_ in the sense that we can't simply reflect on the concepts involved to learn about how they do/don't actually overlap. But I think we have good reason to reject this view: we cannot conceive of an experience that is functionally isolated from--and therefore unavailable to--the subject for whom it is an experience. If this is right, it looks like the experiency and functional senses of consciousness aren't totally distinct after all, since it suggests that there are a priori functional constraints on experience.

---



Imagine that you're experiencing incredible pain right now: a sharp, piercing pain in your lower back. But there's something strange about this pain. It doesn't feature in your mental life in the way that 'normal'[^note] experiences do. It's causally isolated from your other 'conscious' mental processes: you're unable to determine the pain's location (even though you *feel* it in your lower back), you can't describe its qualities (although it *feels* sharp and piercing), and you're unable to notice that your back feels any different from how it normally feels (even though your back does _feel_ very different from the way it normally feels). This pain could continue, and you could go about your day as you normally would without it 'making a difference' or distracting you. You could even sit down to read this paper and think, "Wow, what a horrible scenario!", without realizing that this describes precisely your own situation.

[^note]: I'll use single quotes throughout this introduction to for seemingly natural--but potentially misleading--ways of describing the scenario in question.

This strikes me as a strange sort of pain.

It's not the absence of pain _behavior_ (or any outwardly observable effects) that makes this pain strange. Instead, what's strange is that the pain doesn't show up to *you*: it has no 'inwardly' observable effects. You're not merely doing a great job of masking your pain from others or from yourself; rather, _your_ pain is, in a sense, masked from _you_.

Of course, this isolated pain won't seem so strange were we to conceive of it as belonging to some *other* conscious mind. But that's not the case I've described. This is what's so strange: this pain is in one sense _yours_ (as something within your purview, as something that you're _experiencing_) and in another sense _not yours_ (as something lying outside your purview, as something functionally isolated and 'removed' from your other mental states).

I find it very difficult to figure out what this strange pain must be like. Perhaps my description of this case is illegitimate, or involves some confusion that ought to be corrected. But if we can't resolve the seeming tension at the center of this scenario, that would be illuminating. It would suggest that some functional constraint must be built into our 'experience' concept, that having a pain--or _any_ kind of experience--necessarily involves having a certain kind of 'access' to it.

This is the kind of view I want to make available with this paper. If such a view is right, it would undermine the prevailing wisdom that 'experience' and 'access' are fundamentally different concepts. This would, in turn, obviate recent debates about whether phenomenology overflows cognitive access, and potentially alter our understanding of the structure of both scientific and philosophical inquiries into the nature of consciousness. I'll leave the discussion of these downstream consequences for another time. My focus in this paper will be the plausibility of the standard view just mentioned. Ultimately, I think reflecting on cases of strange experience will make such a view untenable.

# Conceptual Dualism

## Two Ways of Thinking about Consciousness

It's commonly claimed that we can think about mental states as 'conscious' in two separate ways[^opponents]. First, we can think of mental states as _phenomenally_ (p-) conscious: as _'experiency'_, as _feeling_ a particular way, as having a certain _ineffable qualitative character_. Attempts to make this characterization more precise seem to always ground out in synonyms for 'experience'. And that suggests we're dealing with a primitive concept--a concept that can't be given an analysis in simpler terms. So perhaps the best way to get clear on our target is to _gesture at_ paradigmatically _experiency_ experiences (e.g. pain, warmth, anger, visual experience) and draw a contrast with cases where experience seems to drop out of the picture (e.g. dreamless sleep, a coma).

[^opponents]: I have in mind, here, the views of  Nagel (1974), Block (1995), and Chalmers (1996) in particular.

We can also think about mental states as 'conscious' in a _functional_ sense, as _access_ (a-) conscious: as available for arbitrary use within our cognitive economy, as uniquely well-positioned to directly influence one's thoughts and behaviors. Though a-consciousness is sometimes construed as availability for rational control of behavior/verbal report, the possibility of a-conscious non-rational/non-verbal organisms supports the above broader characterization. In specifying a-consciousness, we should try to pick out the feature that _underlies_ or _explains_ how a mental state can be used in reasoning or used in the production of behavior (either verbal or non-verbal). This points us towards a kind of _general_ availability that would, in turn, explain how 'conscious' mental states can be used in a number of different ways.[^access]

[^access]: See Chalmers (1997) for further discussion of these points.

Though there's a good amount of disagreement over how to best characterize this functional sense of 'consciousness', we can put this issue to the side for now. (It'll come back later in a different context.) We can start with the broad 'general availability' characterization, making it more precise if/when needed. But it shouldn't much matter for the line of reasoning I want to pursue in this paper. A-consciousness can remain somewhat vague and we can still mark a clear distinction between between the experiency, how-it-feels sense of 'consciousness' and this functional, how-it-works sense of 'consciousness'. And that kind of distinction is what I'll be focusing on in this paper.

It's worth noting, here, a few couple grammatical points about p-consciousness and a-consciousness.

First, p-consciousness and a-consciousness are categories we apply to mental states in virtue of them being 'conscious' _at all_. To say that a state is p-conscious commits us to the claim that this mental state is associated with _some_ kind of phenomenal character, but nothing more specific. This is why we can make sense of the claim that bats are p-conscious while being unable to make sense of the particular character of the corresponding p-conscious states. (Keep this in mind, as it will be important later on.) Similarly, to say that a state is a-conscious is not yet to commit it to playing any functional role more specific than the very general functional role meant to be picked out by 'a-consciousness'. For example, while you might think that certain kinds of mental states (e.g. pain) will necessarily involve certain kinds of functional roles (e.g. the role which usually causes humans to shout "ouch!", or the role which usually causes avoidance behavior), such roles are *not* implied by the attribution of a-consciousness. Instead, all a-conscious states (e.g. pains, tickles, memories, emotions) share the _very same_ functional trait in virtue of being a-conscious: they are all directly available for general use.

Second, we typically take p-consciousness/a-consciousness to be _relational_ properties, relating individual mental states to the subject/system to whom they belong. So when we say of a mental state that it's p-conscious/a-conscious, there should always be some subject/system for which we're claiming it's p-conscious/a-conscious.[^relational]

[^relational]: Some might question this relational interpretation, but I don't think much hinges on this--I just want to clarify how I'll be using these terms.

## Conceptual Distinctness

The important claim about p-consciousness and a-consciousness on which I'll be focusing is a claim about _conceptual distinctness_. Claims about conceptual distinctness can be easily misunderstood, since they can be taken in two different ways.

First, it can be claimed that two concepts are _weakly distinct_ when they differ in their mode of presentation. For example, the concepts 'square' and 'regular diamond' are weakly distinct because the 'aspects' by which each concept picks out its referent are different.[^weakExamples]

[^weakExamples]: Another example of a (merely) weakly distinct concepts: 'triangle'/'shape with inner angles that sum to 180 degrees'. Note that, as I've laid out this distinction, all strongly distinct concepts will also be weakly distinct.

But, of course, to conceive of a square will be to conceive of something to which the concept 'regular diamond' properly applies. And so some will say that the two concepts are "not _really_ distinct". Though their conceptual overlap may not be _psychologically_ immediate, it is _logically_ immediate. Someone wielding both the 'square' and 'regular diamond' concepts should be able to discover their conceptual overlap merely through a certain kind of reflection, using the very same mental or cognitive resources required to grasp those concepts in the first place. One way to capture this idea is in terms of _a priori entailments_. Because "this is a square" a priori entails "this is a regular diamond" (and vice versa), the distinction between ‘square’ and ‘regular diamond’ is weaker than other conceptual distinctions.

But when such a priori entailments *are* ruled out, the two concepts involved will be 'distinct' in a *stronger* sense: the two concepts may, in fact, overlap in their extension, but their overlap is not guaranteed a priori.[^strongExamples] So 'square' and 'regular diamond' aren't conceptually distinct in this stronger sense, but the concepts 'square' and 'black' are. You can't conceive of a square that's not a regular diamond. But you _can_ conceive of an square that's not black, or an object that's black but not a square. The former case (a non-diamond square) involves a kind of inconsistency that the latter cases do not. Since there's no a priori connection between an object being black and an object being a square, the proper application of the one concept does not, in principle, constrain the proper application of the other.

[^strongExamples]: Further examples of strongly distinct concepts: 'located in region X'/'has shape Y', 'Superman'/'Clark Kent',  'Water'/'H2O'.

This stronger sense of conceptual distinctness is easily misunderstood. For example: "Sure you can conceive of a square which is not yet conceived of as a regular diamond! So aren't they strongly distinct?" or "Even if I can conceive of water without conceiving of it as H2O, that doesn't mean water _can_ be anything other than H2O!". These complaints are misplaced here and arise only if you don't understand this sort of conceptual distinctness in terms of missing a priori connections. To provide a more precise specification of these connections and how they relate to conceptual distinctness: Concepts X and Y are _conceptually distinct_ (in the strong sense) just in case X-claims don't a-priori entail any Y-claims and Y-claims don't a-priori entail any X-claims. (The concepts "square"/"regular diamond" fail this test whereas "square"/"black" pass this test.)

P-consciousness and a-consciousness are, standardly, taken to be conceptually distinct in this stronger sense. (For the rest of the paper, I'll only be talking about this stronger sense, dropping explicit 'in the stronger sense' qualifiers.) It's thought that no amount of reflecting on the concepts 'p-consciousness' and 'a-consciousness' will reveal heretofore unknown constraints on their actual or potential overlap. When conceiving of a mental state as having phenomenal character, you can't discover (by way of reflecting on this feature alone) any functional properties that would fix if/how such a state would be directly available for use. And when we conceive of a mental state as a-conscious and thus playing a particular functional role, we don't think this alone helps us determine whether that mental state has any phenomenal character.[^notMetaphysical]

[^notMetaphysical]: Note that, in marking this _conceptual_ distinction, we aren't hereby committed to a _metaphysical_ distinction between p-consciousness and a-consciousness. Many thinkers accept this conceptual distinction while denying the corresponding metaphysical distinction. (Whether or not this view can be consistently maintained is a separate issue.)

Conceivability plays a crucial _justificatory_ role here. We track the a priori connections that do/don't hold between concepts by applying a fairly anodyne conceivability test: if X-but-not-Y and Y-but-not-X are conceivable, then X and Y are conceptually distinct (they don't share any a priori connections). And if either X-but-not-Y or Y-but-not-X is *in*conceivable, X and Y are *not* conceptually distinct.[^Conceivability]

[^Conceivability]: Chalmers' treatment of conceivability (2002) provides a clear presentation of issues surrounding conceivability. In Chalmers hands, conceivability properly applies to _propositions_, or *statements*, which a reasoner either can or can't grasp. The relevant notion of conceivability, for this paper, is what Chalmers calls _ideal positive conceivability_, under which an ideal reasoner can conclusively conceive of the proposition in question.

So to map this out: the conceptual distinctness of p-consciousness and a-consciousness is to be understood in terms of missing a priori entailments. And the absence/presence of a priori entailments are shown by way of conceivability tests. This forms the theoretical backdrop of the view I want to assess in this paper.[^backdrop]

[^backdrop]: You may have noticed, here, that I've conveniently skated over some important issues about the nature of concepts, the a priori, and conceivability. While I, myself, am sympathetic to criticisms of the standard of understanding of these things, those criticisms shouldn't much matter for our purposes. My aim is to bring out a problem that's *internal* to the standard story, and I take myself to be using these terms in a way that basically aligns with their usage in the relevant literature.

Under this view, when we apply our conceivability test to p- and a-consciousness, we find:

**That some mental state is p-conscious does not a priori entail that that mental state is also a-conscious.** This is shown by the conceivability of states that are p-conscious but not a-conscious. For instance, we can conceive of subjects who enjoy normal visual _experiences_ which are not _available_ to them.

**That some mental state is a-conscious does not a priori entail that that that mental state is also p-conscious.** This is shown by the conceivability of states that are a-conscious but not p-conscious. For instance, we can conceive of philosophical zombies that share our functional organization (and thus have states that are *available* for use in the same way) but lack any and all _experience_.

Put together, these two claims give us what I'll be calling **conceptual dualism**: the view that p-consciousness and a-consciousness don't share a priori connections.

This is all fairly abstract, so conceptual dualism may, as a result, be a bit difficult to pin down. If it helps, you can forget all this talk about a priori entailment and conceivability and, instead, focus on analogies to other strongly distinct concepts. Slot in "square"/"black" for "p-consciousness"/"a-consciousness" and the conceptual dualist position should turn into a view that's quite familiar. Although the concepts "square" and "black" can be applied to the same sorts of things, we can't simply reflect on the squareness (or blackness) of an object and thereby determine whether it's black (or square). So long as we have a grip on what's going on in *this* case of conceptual distinctness, we can use it as a handy model for understanding the conceptual dualist's claims.

## Different Modes of Understanding

Our handy conceivability test helps establish *that* there are no a priori connections between p-consciousness and a-consciousness, but we may still want an account of _why_ such connections don't obtain. I _suspect_ the motivation behind conceptual dualism is a certain naive, intuitively appealing view: the idea  that the first-personal and the third-personal represent two fundamentally different, incommensurable modes of understanding/thinking/conceptualizing/engaging. If you think we deploy these different capacities when thinking of a state as p-conscious, on the one hand, and a-conscious, on the other hand, you'll land on the conceptual dualism. I'll call this the **different capacities hunch**.

If something like this difference-in-mode-of-thought explanation is right, it can help us explain some noteworthy features of the p-consciousness/a-consciousness distinction, as drawn by conceptual dualists. First, it helps explain why p-consciousness and a-consciousness are understood to mark a difference in _everyday_ thought and talk. And it can help us appreciate that the specific formulations of p-consciousness and a-consciousness shouldn't much matter for the issue that we're now focusing on, since there will be missing a priori connections between _any_ first-personal and third-personal understanding of 'consciousness'.[^misfire]

[^misfire]: Another way of putting this point: if we *were* to recognize any a priori functional constraints on experience, those functional constraints would be the natural target of an analysis of 'availability'. So it would be somewhat strange if, in our attempt to find the functional sense of 'consciousness', we misfired and attached 'a-consciousness' to an unrelated functional notion.

# Strange Experiences, Strange Subjects, and More

If conceptual dualism is right and there really aren't any a priori connections that hold between p-consciousness and a-consciousness, we should be able to cook up some truly strange scenarios that (on this view) will still be conceivable.

Let's return to the example I introduced at the start of this paper, an example of what I'll call _strange pain_. What makes this pain so strange is that although you *feel* the pain in all it's glory (i.e. it's p-conscious), the pain is functionally isolated from your other conscious mental states and thus unavailable to you (i.e. it's not a-conscious).

Pain may be particularly evocative, but the strangeness, here, doesn't seem to hinge on the experience being a _pain_ rather than some other kind of experience with a different phenomenal character.[^notSpecific] I could just as easily describe a _strange tickle_ (i.e. an uncomfortable tickle that you _feel_ on your left abdomen but is functionally isolated) or a _strange smell_ (i.e. a pungent rotting corpse odor that you _experience_ but is functionally isolated).

These would each count as particular instances of what I’ll call **strange experiences**: mental states that are p-conscious for some subject but also functionally isolated and therefore unavailable to, not a-conscious for that subject. This gives us a general formula for taking any otherwise 'normal' p-conscious mental state at all and generating a corresponding strange experience by simply 'subtracting' a-consciousness.

[^notSpecific]: Nor does it hinge on the idiosyncratic functional profiles of particular conscious mental states. For instance, even if you think we can conceive of a pain which plays a radically different functional role while still conceiving of the pain _as_ a pain (as David Lewis (1980) claims we can with his Mad Pain ), you should still be able to appreciate the strangeness in _my_ pain example. Instead, I'll want to claim that you can't conceive of a pain as functionally isolated while conceiving of it as an *experience*. This all follows from something I noted about a-consciousness and p-consciousness earlier: these are fully general notions.

Since any p-conscious state can be made strange, and since the (potentially illusory) tension between its phenomenality and its inaccessibility is _internal_ to the particular mental state (that is, the strangeness isn't the result of any _external_ asymmetry between one state's lack of a-consciousness and the presence of a-consciousness in other mental states), we should be able to ‘strangify’ progressively more and more of any given subject’s phenomenal life until all of the subject’s p-conscious mental states have been made strange. So, in addition to individual strange experiences, we can articulate progressively stranger cases:

**Strange experience collection:** A subject has more than one strange experience at once. (e.g. strange pain + strange tickle + strange smell.)

**Strange modality:** An entire sensory modality of a subject goes strange. (e.g. All visual experience is inaccessible.)

**Strange subject:** Every p-conscious state of a subject goes strange. (i.e. The opposite of a philosophical zombie: all p-conscious states and no a-conscious states.)

Let's examine more closely this far end of the strangeness spectrum. What would a strange subject be like?

Strange subjects are the opposite of (philosophical) zombies.[^antiZombie] And just as you can try to conceive of your zombie counterpart, you can also try to conceive of your strange subject counterpart (or, strange twin). Whereas my zombie twin is a physical and functional duplicate that lacks p-consciousness, my strange twin will be a phenomenal duplicate that lacks a-consciousness.

[^antiZombie]: Though strange subjects shouldn't be confused with the "anti-zombies" (Frankish 2007) or "reverse-zombies" (Brown 2010) discussed elsewhere. Interestingly, Frankish and Brown had something very different in mind in their discussion of opposite-of-zombie cases.

Remember, your strange twin will, by definition, share *all* of your p-conscious states. So your total p-conscious experience should be subjectively indistinguishable from your strange twin's. Presuming that you know exactly _what it is like_ to be you, you should already know exactly _what it is like_ to be your strange twin. It should therefore be fairly straightforward to conceive of *this* aspect of strange subjects.

Difficulty emerges when you try to add in a global constraint on the a-consciousness of strange subjects. Strange subjects will share their phenomenology with us, but we're stipulating that none of their p-conscious states are a-conscious. So to conceive of your strange twin, just try to subtract a-consciousness from your own case while leaving all p-conscious aspect of your mental states intact.

This, I think, can bring out a few different worries about the conceivability of strange subjects:

_The Subjective Unity Worry_  
If a strange subject has no access to any of its *own* p-conscious states, if its every experience is isolated from itself, it's difficult to project ourselves into the strange subject's point of view. Is there really any point of view left remaining if nothing is 'presented' to that point of view? Is there really any subject left remaining if the various experiences that 'come together' in a subject can't bear any functional relations to one another and to the subject which owns them? To have a subject at all, perhaps various experiences have to be functionally integrated in order to form a single cohesive subject. In this case, experiences might be said to bear unity relations to one another. And it may also be said that the subject bears an ownership relation to its experiences.

_The Mental Action Worry_  
Even when thinking of a purely phenomenal mind (e.g. a Cartesian Ego), we typically think about such minds as capable of mental action. Minds are *active*, they *do* things, they make decisions, they form judgments, they initiate action, they rehearse mental routines--and all this can be understood entirely from the subject's own 'internal' perspective. It's not clear that *any* of this would be possible for a subject that lacked any and all functional organization. Could a strange subject ever perform a calculation or decide to pursue some action, mental or otherwise? Could a strange subject *feel* like there's some mental activity going on without there actually being any corresponding mental activity? In our own case, it at least *seems* like we directly experience our own cognitive processes and mental activities. Could this sort of experience ever be illusory? And if so, are we only ever _indirectly experiencing_ the effects of 'mental action' without _directly performing_ those mental actions ourselves? If there is a difference between only *seeming* to perform mental actions and *actually* performing mental actions, how could we ever tell the difference?

_The Temporal Relations Worry_  
We typically conceive of subjects as extended through time. Moreover, we typically think that the experiences of a subject at one time are causally related to the experiences of the same subject at time a later time. So subjects, as we typically conceive of them, seem to be temporally structured. Could a strange subject be temporally structured in this way? When a strange subject feels a painful sensation (e.g. the sensation of a punch to the gut), then has a visual experience as of the cause of that sensation (e.g. seems to see their friend Frank punching them), then has an emotional 'response' (e.g. anger at Frank), then feels a desire to take a particular action (e.g. a desire to punch Frank back), and then experiences the performance of that action (e.g the punching of Frank)--could any of these experiences be causally related (given the constraint on functional organization/a-consciousness)? If not, can we make sense of a single strange subject having a sequence of experiences like this? Or must strange subjects, as a result of lacking any functional structure which would maintain them through time, exist only instantaneously?

I, myself, don't feel each of these worries to the same degree. (I only really feel the pressure of the subjective unity worry.) But any of these worries (or others that I haven't considered) can, I think, provoke an intuition that conceiving of a phenomenal mind already involves the conception of some kind of underlying functional structure in which various experiences are embedded and through which they bear relations to one another. What I hope this brings out, if only in a very rough way, is an intuition that we don't conceive of the ebb and flow of experience as being unconstrained by structural or causal relations, that we often *do* apply a structural/functional/causal lens in thinking about the collection of experiences which comprise a given subject. I'll call this the **structured subject intuition**. Any view that takes this intuition seriously will, inevitably, reject conceptual dualism and replace it with the view that p-conscious states, in virtue of being p-conscious, must already admit of particular functional relations, that p-consciousness facts a priori entail a-consciousness facts. The central motivation driving such views is the idea that our concept of "mind", of "subject", is of a certain kind of functional, structured system.

I want to note a couple things about the structured subject intuition. First, to think of a subject as structured or as admitting of functional organization is not yet to think of that subject as having _physical_ structure. So we're not here concerned about the distinction between the phenomenal and the physical. As the intuition goes, in conceiving of a subject through the experiency lens, the experiency lens alone already reveals some abstract structural/functional features of subjects and experiences. If the intuition is right, then the experiency lens is a *kind* of functional lens (just as the physical lens might be said to be a kind of functional lens).

Second, while I've used the example of strange subjects to bring out the structured subject intuition, it can also be brought out for any case lying on the spectrum of strangeness introduced above. The difficulties we run into with strange subjects should be precisely the same as those we have with single strange experiences. Each worry at the global level should turn up at the local level:

- _The Local Subjective Unity Worry:_ How can a strange experience (like a particular strange pain) be part of or be owned by the subject which for whom its an experience?  
- _The Local Mental Action Worry:_ How could a strange experience  play any role in mental activity?  
- _The Local Temporal Relations Worry:_ How could a strange pain be part of any temporally extended causal chain or endure through time?  

But any underlying uneasiness is, I think, better brought out in the case of strange subjects. Whereas subjects are isolated from only _one_ of their mental states when a particular experience of theirs goes strange, strange subjects are isolated from the _entirety_ of their phenomenology. It's one thing to be estranged from a small portion of one's total experience. It's something else to be estranged from _all_ experience. And while we may find clever ways to convince ourselves that 'hidden' phenomenology is okay in particular instances, it's much harder to make it seem okay that *all* of our phenomenology could be 'hidden'.

Last, while my discussion will be focused on the broad class of strange experiences described above (ranging from individual strange experiences to strange subjects), the structured subject intuition can *also* be brought out, I think, with other related thought experiments. Here are some other fun cases that are worth pondering:

_Strange Modality Expansion_  
A subject has an additional strange modality of which they are not 'aware'? Consider, for instance, that you, yourself, have a strange modality which gives you a bat's sonar experiences. But these bat-like experiences would, nonetheless, be inaccessible to you. (And if you don't think this is your actual situation, how do you know that this is not your actual situation?)

_Strange Swapping_  
Two different subjects are a-conscious of the *other* subjects p-conscious states. (Or vice versa: two different subjects are p-conscious of the *other* subject's a-conscious states.) For instance, consider a case in which 'you' are currently experiencing the life of someone else while also taking actions informed by 'your own' mental states and making decisions about your own life.

_Strange God_  
Consider a subject who 'has' every experience in the world (i.e. my experiences, your experiences, a bat's experiences, a dolphin's experiences, etc.) but is unable to access any of them. Similarly, consider a subject who has all experiences in the world but can only access the experiences of a single organism (e.g. you experience everything but are only a-conscious of 'your' p-conscious states.)
	
---

Insofar as any of these cases make you pause, it's worth figuring out whether or not that means you are implicitly committed to some a priori functional constraints on experience. With the structured subject intuition, I tried to provide an initial sketch of what might motivate an alternative to conceptual dualism. That alternative ought to refined and developed into a more careful philosophical position, and want to try to do that in a separate paper. But the particulars of that positive account need not be settled in order to make a negative case against conceptual dualism.

# Can Strange Experiences be Made Palatable?

At first blush, strange experiences present conceptual dualists with a challenge. I suspect many will share my intuition that strange experiences are *not* conceivable. And if strange experiences are not conceivable, conceptual dualism seems to lose its justificatory support. Without a positive conceivability verdict for cases of p-consciousness without a-consciousness, it's unclear whether the corresponding a priori entailment obtains. Consequently, it's unclear whether there's really a clean distinction between thinking of 'consciousness' in an experiency way and thinking of 'consciousness' in a functional way. To block this line of reasoning and secure the support necessary to get their view up and running, conceptual dualists need to explain what's mistaken in skepticism about the conceivability of strange experiences.

So how might we respond to the strange experience challenge on behalf of conceptual dualism?

## 'Radical' A Priori Skepticism

We can pretty quickly rule out strategies which try to undermine this challenge by way of 'radical' skepticism about conceivability and the a priori:

"Why be so sure that there's some fact of the matter about whether strange subjects are conceivable? Not all concepts are well-behaved: they sometimes 'break down', no longer 'guide' us, and leave us unsure about how to apply them. It would be a mistake to insist that there be some clear verdict on whether a concept applies in such problem cases."

This sort of approach pretty clearly can't be used in the present context, in support of conceptual dualism. It proves too much: it undermines the philosophical framework that was used to get conceptual dualism going in the first place. Conceptual dualism *needs* the 'anodyne' conceivability test described earlier (and the related more-or-less-standard understanding of the a priori) in order generate the claims that make up the view.

## Different Notions of Access

We might question whether strange experiences, as described, *really* present us with a case of p-consciousness without a-consciousness. If we make available a revised and updated conception of a-consciousness--one which makes clearer the stark contrast between a-consciousness and p-consciousness--perhaps it will be easier to see that strange experiences really are conceivable. Here are two candidates for the 'correct' notion of a-consciousness:

_Accessed/Accessible_  
We can distinguish between mental states that are _actually accessed_ from those which are _merely accessible_. And if we understand 'a-conscious' to mean 'actually accessed', then it's easier to accept that there can be p-conscious states that don't become a-conscious.[^seeBlock]

[^seeBlock]: Block, for instance, seems to pursue this kind of strategy in some places:

	"Importantly, the [phenomenal] overflow argument does not claim that any of the items in the array are cognitively inaccessible, but rather that necessarily most are unaccessed. For comparison, consider the following: not everyone can win the lottery; however, this does not show that for any particular contestant the lottery is unwinnable. In other words, to say that necessarily most items in the array are not accessed is not to say that any are inaccessible." (Block 2011, p. 576)

	“Many critics of the overflow argument seem to think that a vote for overflow is a vote for inaccessible consciousness. ...However, as pointed out earlier, the fact that necessarily most items are not accessed does not entail inaccessibility of any items.” (Block 2011, p. 583)

_Fancy/Folky_  
We can distinguish between _fancy_ 'theory-laden' formulations of a-consciousness that rest on work in cognitive science and _folky_ formulations of a-consciousness that capture some pre-theoretical,  everyday notion of 'access'. Since the theory-laden way of conceiving of mental states may be far removed from how the folk think about them (it'll involve lots of additional commitments about the functional structure of our mental machinery), this sense of a-consciousness clearly isn't tied up with in our everyday p-consciousness concept.

The basic problem with these approaches is that they merely relocate, rather than remove, the challenge. I'll specifically address the accessed/accessible version of this objection, but my reply to both versions should have the same shape.

Replacing a constraint that _all p-conscious states must be accessed_ with a constraint that _all p-conscious states must be accessible_ does nothing to remove the worry that p-conscious states might have _some_ a priori functional constraints. Accessibility is, after all, a functional notion. You could, of course, drop the accessibility constraint too, but then the accessed/accessible distinction isn't doing any work here to make it any *easier* to address the challenge. So I suspect that those drawn to this objection misunderstand the structure of the issue at hand.

This maneuver is akin to pointing to some shape property--say, having some right angles--that blackness *does* a priori entail, and using that to get around worries over whether blackness a priori entail squareness. Conceptual dualism is interesting and significant insofar as it rules out a priori entailments between p-consciousness and _any_ functional properties.

(In my view, the accessed/accessible distinction is not very useful and somewhat confusing  because 'access' is not a particular kind of use. If we understand a-consciousness as conferring a special status that allows an mental state to be used for a wide range of purposes, then it's unclear what the contrast between _potentially_ a-conscious states and _actually_ a-conscious states comes to.)

## Dimmed Experience

I suspect that some people, when confronted with my strange experience cases, will try to point to a class of _actual_ cases of p-consciousness without a-consciousness with which we're already well-acquainted. For instance, Block has made appeals along these lines:

"Suppose you are engaged in intense conversation when suddenly at noon you realize that right outside your window there is--and has been for some time--a deafening pneumatic drill digging up the street. You were aware of the noise all along, but only at noon are you consciously aware of it. That is, you were P-conscious of the noise all along, but at noon you are both P-conscious and A-conscious of it. ...[This] is a pure case of P-consciousness without A-consciousness" (Block 1995, p. 234)

It's easy to find further examples of this sort of thing, instances of some experience that has receded into the periphery of our phenomenology. We typically have no difficulty calling such 'dimmed' experiences _experiences_, but such experiences may not be a-conscious in the way that other experiences are. As the thought goes, since such experiences are not at the forefront of our attention, they may easily pass by without us actually 'accessing' them. So we, perhaps, have _actual_ cases of p-consciousness without a-consciousness--even better than merely conceivable cases.

We should be able to disarm this sort of maneuver with some of the insights gleaned from the above discussion of the accessed/accessible distinction. Dimmed experiences, as described, look more like 'unaccessed' but still 'accessible' mental states. And I think it would be much less clear that these were really experiences if they were totally unavailable/inaccessible. While I don't find the accessed/accessible distinction all that helpful, it's clear that the class of states we're trying to target with 'a-consciousness' are the very same states others have tried to target with the 'accessible' label. So this sort of objection will fail for the same reasons the earlier objections failed: it doesn't address the claim that p-consciousness is tied to the functional notion of accessibility.

(Dimmed experiences, intuitively, are available in ways that completely unconscious states and processes are not available. We think, "there was some aspect of my experience that has been there for awhile and nothing was stopping me from foregrounding that experience". Unconscious states and processes, we think, are unconscious precisely because they aren't "at the ready" in this way. And so there's a functional difference between merely-dimmed experiences and fully-extinguished experiences.)

## Unimaginable, Not Inconceivable

Leaving disagreements over the notion of a-consciousness behind us, conceptual dualists might pursue a line of defense centering on the notion of conceivability:

"Are we sure that we run into any tension just in _conceiving_ of an inaccessible experience? It's more likely that what gets us into trouble is an act of _imagination_--and that's separable from the any act of _conceiving_. When we try to simulate what a strange experience would feel like and then 'check on' this simulated experience, we, unsurprisingly, *always* find such experiences to  be a-conscious--'checking on' an experience is a paradigmatic a-conscious act! That we find ourselves lapsing into imagination in these cases is understandable--it's quite a handy tool when trying to understand others' experiences. But in the present context, this knee-jerk appeal to imagination leads us astray, and we're mistakenly pulled towards the Structured Subject Intuition as a result."

Before I get to my main response, I want to note that this line of reasoning doesn't yet provide any support for a *positive* conceivability verdict. It merely explains away the supposed _negative_ conceivability verdict. And the conceptual dualist's positive story, here, would have to avoid the lazy "well you can just put the two concepts side-by-side" idea, for this is exactly the kind of bad reasoning that supports the conceivability of a non-pythagorean triangle ("Well you just whisper to yourself 'this triangle does not obey the pythagorean theorem' while imagining a right triangle"). So for this objection to work, it would need an additional independently motivated story in support of the positive conceivability claim. Without such a story, we've lost any motivation for adopting conceptual dualism over alternative views.

But to address the substance of this objection: it's important to recognize that our ‘experience’ concept can be applied without actively imagining or conceiving of any _particular_ kind of experience. This follows from a general point about our 'experience' concept briefly gestured at earlier: 'experience' is a determinable, not a determinate. Consequently, it's easy to conceive of a state being p-conscious while leaving its precise phenomenal character unspecified. For instance, we can make sense of the claim that bats enjoy uniquely-batty experiences, and this doesn’t require any insight into the particular nature of any of these experiences. Furthermore, I take it that bat-owned strange experiences are just as inconceivable as human-owned strange experiences. Could a bat enjoy an experience associated with some functionally-isolated state, like some state in a different bat’s head? Such a case is, to my lights, just as intuitively implausible as the strange pain case described earlier. In this way, I think we can demonstrate that the imaginability/unimaginability of particular kinds of experiences plays no essential role in our assessment of strange experience cases.

## Bare Denial and Beyond

For conceptual dualists who remain unmoved by the strange experience challenge, one last refuge remains:

"You're right that the above objections can't be used to decisively cut off skepticism about conceptual dualism. But I still don't see what's so unacceptable about embracing the conceivability of strange experiences. This is just how these things go sometimes. When intuitions diverge over basic conceptual 'starting points'--presuming that we really have the same concept in mind and are not talking past one another--all that's left is a familiar sort of bare disagreement. And while it doesn't look like this issue can be settled by any further analysis, that doesn't mean we don't already have enough evidence to support a positive conceivability verdict. You say you can't conceive of inaccessible experiences, but you're _just wrong_. And recognizing this involves nothing more than exercising one's competence in wielding the concepts involved."

While I do want to acknowledge this sort of flat-footed objection as a possible view, I don't myself take it very seriously. And I'm hoping that you'll better understand my position if I run through an 'argument' that's structurally  similar to mine: Hilary Putnam's super spartans/X-worlders argument against analytical behaviorism (1963).

Putnam's argument works by carefully demonstrating the full range of consequences that follow from accepting analytical behaviorism. The hope is that, when this is all laid out clearly, analytical behaviorism no longer looks so attractive. Because we have prima facie commitments to the plausibility of super spartans/x-worlders, and because analytical behaviorism directly entails the implausibility of these prima facie plausible scenarios, the view, itself, became implausible.

Note that there's no meaningful sense in which analytical behaviorists were *forced* into admitting defeat in the face of such a challenge. Analytical behaviorism can be made to accommodate the necessary consequences, but such attempts, to an outside observer, are bound to appear ad hoc, motivated out of desperation to save the view.

So the strategy behind Putnam's argument, and mine, is: start with some judgments that are treated as certain, and build a theory on the basis of these certain commitments. Those who disagree with these certain commitments are wrong ‘from the start’, and their mistake can't be explained by appealing to some independent ‘data’. There *is* no such independent source of support, nor *can* there be. So long as we've done out best to rule out conceptual confusion, any leftover disagreement can only be the result of fundamental, ground-level misunderstanding.

But there's one important disanalogy between Putnam's argument and mine: Unlike analytical behaviorism, conceptual dualism is quite frequently taken as an uncontroversial background commitment in  philosophical discussions of consciousness. So while a stalemate might not have represented progress for the opponents of analytical behaviorism, I hope a stalemate, here, will represent a kind of progress--if only for contingent, historical reasons.

By reexamining conceptual dualism and dislodging it from its privileged position–-by foregrounding an issue that has been obscured and ignored–-we open up and make available views that weren't previously given proper consideration. A reconsideration of such views can have a number of downstream consequences for issues the framing of which took conceptual dualism for granted, either implicitly or explicitly. And by reshaping the terrain of the debate in this way, newly-available views may consequently be seen as more attractive-–they may help solve problems which, under the old framework, were thought to be unsolvable or otherwise very difficult. Even small victories of this sort would provide inductive support for rejecting conceptual dualism.

With that meta-theoretical story out of the way, I'll wrap things up with a brief sketch out the alternative path I'm proposing we take.

# Following the Structured Subject Intuition

If strange experiences are deemed inconceivable, that suggests that p-conscious mental states must, a priori, be a-conscious. Because the notion of a-consciousness was, itself, left a little uncertain, the precise nature of the functional constraints on experience still need to be spelled out. However, I think it's a mistake to get hung up on this leftover task, since the basic idea that there are functional constraints built into the notion of experience already has some interesting consequences.

A few clarifications should allow us to better appreciate the basic view I have in mind.

First, this view should not be mistaken for analytical functionalism, which is a *much* stronger view. While analytical functionalism holds that *all* mental though/talk can be _reduced_ to functional though/talk, the view in question only claims that the determinable concept of 'experience'/'p-consciousness' brings along with it certain functional constraints. It need not be the case that such a concept can be given an exhaustive analysis in functional terms. (I, myself, would reject the possibility of such an exhaustive analysis, but this possibility is left open by the view.) Nor does the view require that more determinate phenomenal concepts (e.g. "pain", "visual experience", "joy") bring along with them  more determinate functional constraints. So while this view will say that a token pain state is, a priori, a-conscious, that does hardly anything to settle the particular functional profile of that token state.

Second, this view is only concerned with one of the two a priori entailments that conceptual dualists deny: the p-consciousness-to-a-consciousness entailment. Accepting this entailment does not commit us to accepting the other direction of entailment. So this view doesn't rule out the conceivability of philosophical zombies. (I, myself, reject the a-consciousness-to-p-consciousness entailment, but the view in question requires no such commitment.)

Third, it's important to remember that this is a view about the _concept_ of--not the metaphysics of--experience. So the view is committed neither to materialism (since one can, in principle, combine functionalism with dualism), nor to phenomenal realism (since it remains to be seen if there's anything in reality to which our 'experience' concept applies).

That said, a revision to our understanding of the 'experience' concept will, necessarily, trigger revisions to our understanding of the metaphysics and epistemology of experience. In particular, this view introduces, for free, functional 'hooks' for experiences, and I think that can simplify otherwise-frustrating hurdles that get in the way of a science/metaphysics of mind. I'll quickly mention just a couple such potential consequences. First, we might be able immediately rule out panpsychism as a plausible metaphysical view since many of the states which would count as p-conscious under this view seem to violate the sorts of functional constraints being introduced. Second, we might be able to rule out views like Dan Dennett's multiple drafts theory of consciousness, since such a theory would, at best, require positing multiple minds for which each 'draft' stands in the right functional relation.

While I think this is much less clear, this view might also undermine certain conceptions of the subjective/objective distinction. This is a slippery issue that ought to be discussed with much greater care, but, for now, I'll provocatively assert: The view I've been defending is in line with the observation others have made that all thought is objective. There is no special 'subjective' point of view that we can take up in thought, a point of view which is contrasted against an 'objective' point of view. One can have a point of view in terms of which particular concepts one has or which particular thoughts one forms with these concepts. But those thoughts and concepts must, essentially, be point-of-view-less. In short, I think my preferred view can help us reject the different capacities hunch, which posits irreconcilable modes of thinking. Instead, all thought is, necessarily, unified.

Whether or not such a view can really be developed into full-fledged philosophical position remains to be seen. But my hope is that, with this paper, I've raised doubts about the plausibility of conceptual dualism and opened the door for an attractive alternative view.

# References

Block, Ned (1995). On a confusion about a function of consciousness. Brain and Behavioral Sciences 18 (2):227-–247.

Block, Ned (2011). Perceptual consciousness overflows cognitive access. Trends in Cognitive Sciences 15 (12):567-575.

Brown, Richard (2010). Deprioritizing the A Priori Arguments against Physicalism. Journal of Consciousness Studies 17 (3-4):47-69.

Chalmers, David J. (1996). The Conscious Mind: In Search of a Fundamental Theory. Oxford University Press.

Chalmers, David J. (1997). Availability: The cognitive basis of experience? In Ned Block, Owen J. Flanagan & Guven Guzeldere (eds.), The Nature of Consciousness. MIT Press 148-149.

Chalmers, David J. (2002). Does conceivability entail possibility? In Tamar S. Gendler & John Hawthorne (eds.), Conceivability and Possibility. Oxford University Press 145--200.

Frankish, Keith (2007). The anti-zombie argument. Philosophical Quarterly 57 (229):650–666.

Lewis, David (1980). Mad pain and Martian pain. In Ned Block (ed.), Readings in the Philosophy of Psychology. Harvard University Press 216-222.

Nagel, Thomas (1974). What is it like to be a bat? Philosophical Review 83 (October):435-50.

Putnam, Hilary (1963). Brains and behavior. In Ronald J. Butler (ed.), Analytical Philosophy: Second Series. Blackwell.
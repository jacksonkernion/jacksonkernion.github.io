---
title: Minds and Machines
layout: post
---

# Converging on Cognition v0.1: The Dynamical Structure of Intelligence
<i class="fa fa-calendar"></i> Wednesdays, 3:00m–5:00pm  
<i class="fa fa-map-marker"></i> 66-154

This seminar will bring together ideas from Philosophy, Cognitive Science, and Artifical Intelligence, with the aim of constructing a general theory of cognition. Such a theory should have both a descriptive component (What is a cognitive system?) and a normative component (Which cognitive strategies work well in which situations? And how ought an intelligent reasoner choose a cognitive strategy, given their cognitive situation?). And if such a theory is not (yet?) possible, we should be able to explain why.

The sorts of questions that will guide us:

- Is there such a thing as *general* intelligence?
- Are there different *forms* or *domains* of intelligence? If so, what might they be?
- What does 'ideal' reasoning look like? Must all reasoning be non-ideal?
- How are the static norms of logic related the dynamical norms of reasoning?

---

Some potential readings:

- David Chalmers, Constructing The World
- Frank Jackson, From Metaphysics to Ethics
- Jane Freidman, “The Epistemic and the Zetetic”
- Gilbert Harman, Change in View
- Gilbert Harman and Sanjeev Kulkarni, Reliable Reasoning
- Michael Strevens, “Remarks on Harman and Kulkarni's ‘Reliable Reasoning’”
- Kevin Kelly, “Review of Reliable Reasoning" 
- Kevin Kelly, “Ockham’s razor, empirical complexity, and truth-finding efficiency"
- Kevin Kelly, “Justification as Truth-Finding Efficiency: How Ockham’s Razor Works.”
- Kevin Kelly, "Epistemic Rationality as Instrumental Rationality: A Critique"
- Konstantin Genin and Kevin Kelly, “Learning, Theory Choise, and Belief Revision”
- Sutton and Barto, Reinforcement Learning: An Introduction
- Lake and Baroni, "Generalization without systematicity”
- Brendan Lake, "Building Machines That Learn and Think Like People"
- Mikolov, Joulin, and Baroni, "A roadmap to machine intelligence"
- Griffiths and Tenenbaum, "Theory-Based Causal Induction"
- Lieder and Griffiths, “Resource-Rational Analysis”
- Ho, Abel, Griffiths, and Littman, “The Value of Abstraction”
- Laura Franklin-Hall, “Natural kinds as categorical bottlenecks”
- Nakkiran et al., “Deep Double Descent: Where Bigger Models and More Data Hurt” 
- Robert Long, “Nativism and Empiricism in Artificial Intelligence”


---

For more information, and to have a say in which direction we take the course, come to the brief organizational meeting on Wednesday, February 5.
